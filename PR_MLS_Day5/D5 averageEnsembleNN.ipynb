{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit high variance mlp on blobs classification problem\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# learning curves of model accuracy\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demonstrate high variance of mlp model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# fit and evaluate a neural net model on the dataset\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "    # evaluate the model\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    return test_acc\n",
    " \n",
    "\n",
    "# repeated evaluation\n",
    "n_repeats = 20\n",
    "scores = list()\n",
    "for _ in range(n_repeats):\n",
    "    score = evaluate_model(trainX, trainy, testX, testy)\n",
    "    print('> %.3f' % score)\n",
    "    scores.append(score)\n",
    "# summarize the distribution of scores\n",
    "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))\n",
    "# histogram of distribution\n",
    "pyplot.hist(scores, bins=10)\n",
    "pyplot.show()\n",
    "# boxplot of distribution\n",
    "pyplot.boxplot(scores)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of model averaging ensemble on blobs dataset\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "    return model\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = array(yhats)\n",
    "    # sum across ensemble members\n",
    "    summed = numpy.sum(yhats, axis=0)\n",
    "    # argmax across classes\n",
    "    result = argmax(summed, axis=1)\n",
    "    return result\n",
    "\n",
    "# evaluate ensemble model\n",
    "def evaluate_members(members, testX, testy):\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(members, testX)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "trainy = to_categorical(trainy)\n",
    "\n",
    "# repeated evaluation\n",
    "n_repeats = 20\n",
    "n_members = 5\n",
    "scores = list()\n",
    "for _ in range(n_repeats):\n",
    "    # fit all models\n",
    "    members= [fit_model(trainX, trainy) for _ in range(n_members)]\n",
    "    # evaluate ensemble\n",
    "    score = evaluate_members(members, testX, testy)\n",
    "    print('> %.3f' % score)\n",
    "    scores.append(score)\n",
    "# summarize the distribution of scores\n",
    "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show Variance of MLP Model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "pyplot.hist(scores, bins=10)\n",
    "pyplot.show()\n",
    "# boxplot of distribution\n",
    "pyplot.boxplot(scores)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
